\section{Experimental Setup}
\label{sec:experimentalSetup}

We evaluated our implementation using trace-based simulation on traces
collected from controlled experiments conducted with our robotic
testbed as well as limited traces collected from human subjects.
While our robotic testbed allows us to run live experiments, we chose
instead to use trace-based simulation for several reasons.  First, it
took the robot close to an hour to complete a single experiment.  A
thorough exploration of the configuration space of the various sensing
approaches we consider would have required over a year of continuous
live experiments.  Moreover, taking fine grain power consumption
measurements while the robot is in motion is not trivial.

\subsection{Trace Collection}

We collected our traces by having the robot perform multiple runs with
a prototype smartphone attached to it back.  The smartphone ran an
application that kept the device always awake and continuously recorded
accelerometer readings for all three axes.  Each run generated a
trace that included timestamps for the start and end of each action
performed by the robot (which we use as the ground truth for our
experiments) and a list of timestamped acceleration readings.

In each run, the robot performed five different actions: standing
idle, walking, sit-to-stand transitions, stand-to-sit transitions, and
headbutt.  We created runs with three different levels of activity.
Runs in groups 1, 2 and 3 spent 90\% , 50\% and 10\% of the time
standing idle, respectively. The reminder of the time was allocated as
follows: 73\% for walking, 24\% for transitions between sitting and
standing, and 3\% for headbutts.  This setup allows us to experiment
with detecting actions that are common, somewhat frequent, and rare.
In total, the robot executed 18 different runs: 9 for group 1, 6
for group 2 and 3 for group 3.  We generated more runs for groups 1
and 2 because of the lower activity levels compared to group 3. To
eliminate bias, the list of actions was generated randomly for each
run, based on the expected probabilities of each action occurring.

In addition, to validate the applicability of our results to human
scenarios, we collected six hours worth of accelerometer traces from
three different individuals while they perform routine daily
activities: morning commute using public transit, walking in a retail
store, and walking in an office.  Between 20\% and 37\% of each trace
is spent walking.



\begin{table*}[t]
\centering
    \begin{tabular}{|l|l|l|l|}
	\hline
    Action      					& Data Filter 									& Threshold(s) \\ \hline
    Steps     					& EMA (alpha = 50\%) 						& x-axis $\geq 2\:m/s^2$ 		\\ \hline
	Headbutts   					& FFT (relative energy threshold = 10\%) 	& y-axis $\leq -3.5\:m/s^2$ 		\\ \hline
	\multirow{2}{*}{Transitions} 	& \multirow{2}{*}{EMA (alpha = 10\%)}		& $2.25\:m/s^2 \leq$ y-axis $\leq 3.25\:m/s^2$ 	\\ 
									&												& $8.2\:m/s^2 \leq$ z-axis $\leq 9.2\:m/s^2$ 	\\ \hline
    \end{tabular}
	\caption{Best performing Smartsensor wake-up conditions.}
	\label{table:WUCparameters}
\end{table*}


\subsection{Sensing Approaches}

We replayed each trace under the following sensing approaches:

\textbf{Always Awake} The applications keep the phone awake all the
time, constantly collecting accelerometer readings.  This setup
achieves the highest detection
recall\footnote{$Recall=TruePositives/(TruePositives+FalseNegatives)$}
and
precision\footnote{$Precision=TruePositives/(TruePositives+FalsePositives)$}
and provides a baseline for comparison.

\textbf{Duty Cycling} We modified the applications so that they check
sensor readings periodically and then put the phone to sleep.  On
wake-up, the phone is kept awake for 4 seconds in order to collect
sensor data.  If an action is detected, the phone is kept awake for
another 4 second, and goes to sleep otherwise.  This software only
implementation runs on any mobile device and does not require special
hardware support.

\textbf{Batching} This configuration emulates hardware support
available on the Nexus 5 for collecting and batching accelerometer
readings while the main processor sleeps.  The application wakes up
periodically, reads the batch of sensor readings, runs the detection
algorithm, and goes back to sleep.

\textbf{Predefined Activity} This configuration emulates hardware
support available on the Moto X for recognizing a limited number of
predefined activities.  For this purpose, we hard-coded the
Smartsensor board as a {\em step detector} (EMA filter with $alpha =
50\%$ and x-axis $\ge 2 m/s^2$).  The applications register an event
handler for the {\em step activity} and put the phone to sleep.  On
wake-up, the applications acquire a batch of sensor readings, run
their detection algorithm, and go back to sleep.

\textbf{Smartsensors} We let applications define their own custom wake-up 
condition by selecting a filter among the predefined set described
in Section~\ref{sec:prototype} and setting the filter's configuration
parameters and thresholds .  The applications register an event handler
for the custom event of interest and put the phone to sleep.  On
wake-up, the applications acquire a batch of sensor readings from the
Smartsensor, run their detection algorithm, and go back to sleep.
Table~\ref{table:WUCparameters} shows the wake-up condition for each
application that achieves the lowest power consumption while matching
the detection recall of the Always Awake approach.

\textbf{Oracle} A hypothetical ideal implementation that only wakes up
when an event of interest occurs.  Such a wake-up condition would
achieve the same detection precision and recall as Always Awake, with
the lowest possible energy consumption. The difference between the
power consumption of this method and the Smartsensors approach
provides an upper bound on the potential additional benefits of custom
code offloading.

For each sensing approach and trace, we measured the amount of sleep
and awake time, the total number of wake-up events, and the recall and
precision of the application.  Finally, we used an energy model
derived from measurements of our Smartsensor prototype to estimate
the average power consumption.  For experiments with {\em Always Awake}
and {\em Duty Cycling}, the power model accounts only for the energy
consumption of the Nexus 4.  For {\em Batching} and {\em Predefined Activity},
the model also includes the cost of the low-power TI MSP430
micro-controller.  Finally, experiments that use {\em Smartsensors} and {\em
  Oracle} include the cost of either the TI MSP430 or the TI Stellaris
LM4F120H5QR, depending on the application being evaluated.








