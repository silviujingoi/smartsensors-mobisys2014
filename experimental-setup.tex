\section{Experimental Setup}
\label{sec:experimentalSetup}

We evaluated our implementation using trace-based simulation on traces
collected from controlled experiments conducted with our robotic
testebed as well as limited traces collected from human subjects.
While our robotic testbed allows us to run live experiments, we chose
instead to use trace base simulation for several reasons.  First, it
took the robot close to an hour to complete a single experiment.  A
thorough exploration of the configuration space of the various sensing
approaches would have required over a year of continuous live
experiments.  Moreover, taking fine grain power consumption
measurements while the robot is in motion is not trivial.

\subsection{Trace Collection}

We collected our traces by having the robot perform multiple runs with
a prototype smartphone attached to it back.  The smartphone ran an
application that kept the device always awake and continuously recorded
accelerometer readings for all three axises.  Each run generated a
trace that included timestamps for the start and end of each action
performed by the robot (which we use as the ground truth for our
experiments) and a list of timestamped acceleration readings.

In each run, the robot performed five different actions: standing
idle, walking, sit-to-stand transitions, stand-to-sit transitions, and
headbutt.  We created runs with three different levels of activity.
Runs in groups 1, 2 and 3 spent 90\% , 50\% and 10\% of the time
standing idle, respectively. The reminder of the time was allocated as
follows: 73\% for walking, 24\% for transitions between sitting and
standing, and 3\% for headbutts.  This set-up allows us to experiment
with detecting actions that are common, somewhat frequent, and rare.
In total, the robot executed 18 different runs: 9 for the group 1, 6
for group 2 and 3 for group 3.  We generated more runs for groups 1
and 2 because of the lower activity levels compared to group 3. To
eliminate bias, the list of actions was generated randomly for each
run, based on the expected probabilities of each action occurring.

In adition, to validate the applicability of our results to human
scenarios, we collected six hours worth of accelerometer traces from
three different individuals while they performe routine daily
activities: morning commute using public transit, walking in a retail
store, and walking in an office.  Roughly 20\% to 45\% of each trace
is spent walking.

\subsection{Sensing Approaches}

We simulated each trace for each of the following sensing approaches:

\textbf{Always Awake} The applications keep the phone awake all the
time constantly collecting accelerometer readings.  This setup
achieves the highest detection
recall~\footnote{$Recall=TruePositives/(TruePositives+FalseNegatives)$}
and
precision~\footnote{$Precision=TruePositives/(TruePositives+FalsePositives)$}
and provides a baseline for comparison.

\textbf{Duty cycling} We modified the applications so that they check
sensor readings periodically and then put the phone to sleep.  On
wake-up, the phone is kept awake for 4 seconds in order to collect
sensor data.  If an action is detected, the phone is kept awake for
another 4 second, and goes to sleep otherwise.  This software only
implementation runs on any mobile device and does not require special
hardware support.

\textbf{Batching} This configuration emulates hardware support for
collecting and batching accelerometer readings while the main
processor sleeps (e.g. Nexus5).  The phone wakes up periodically,
reads the batch of sensor readings, runs the detection algorithm and
goes back to sleep.

\textbf{Predefined Activity} This configuration emulates hardware
support for recognizing a limited number of predefined activities
(e.g., MotoX).  For this purpose, we hardwired the smartsensor as a
{\em step detector} (EMA filter with alpha = 50\% and x-axis > 2
$m/s^2$).  The applications register an even handler for the {\em step
  activity} and put the phone to sleep.  On wake-up, the applications
acquire a batch of sensor readings from the smartsensor, run their
detection algorithm, and go back to sleep.

\textbf{Predefined Filters} We let application define their own custom
wake up condition by selecting a filter among the predefined set described
in Section~\ref{sec:prototype} and setting the filter's configuration
parameters and thresholds .  The applications register an even handler
for the custom event of interest and put the phone to sleep.  On
wake-up, the applications acquire a batch of sensor readings from the
smartsensor, run their detection algorithm, and go back to sleep.

\textbf{Oracle} A hypothetical ideal implementation that only wakes up
when an event of interest occurs.  Such a wake-up condition would
achieve the same detection precision and recall as Always Awake, with
the lowest possible energy consumption. The difference between the
power consumption of this method and the method using custom
filter-based wake-up conditions gives an upper bound on the potential
benefits of fully configurable hardware, beyond limited data filter
selection.

For each sensing approach and trace, we measured the amount of sleep
and awake time, the total number of wake-up events, and the recall and
precision of the application.  Finally, we used an energy model
derived from measurements of our smartsensor prototype to estimated
the average power consumption.  For experimens with {\em Always Awake}
and {\em Duty Cycling}, the power model accounts only for the energy
consumption of the Nexus 4.  For {\em Batching} and {\em Activity},
the model also includes the cost of the simple TI MSP430
micro-controller.  Finally, experiments that use {\em Filter} and {\em
  Oracle} include the cost of either the TI MSP430 or the TI Stellaris
LM4F120H5QR, depending on the application being evaluated.








